# Week two report
On this week on ParrotailIPT2018 learned about various concept of deep learning, optimization, regularization,CNN, RNN those
concepts were covered on this week. The various books, article and videos of deep learning which learned in older to reach the goal
of covers this concept. The book which  got concept was Dropbox_Cholletand videos which implemented by Andrew NG. Through this
on deep learning it come to solve the problem which machinelearning fail to solve such as image captioning, music generation, machine
translation speech recognition, automatictest generation. Pytorch this is frame work of deep learning which selected to learning and 
implemented due to this more powerful compare to Tensor Flow due to the is better for rapid prototype in research, small scale project, 
graph creation and debugging due to the dynamic computation graph.

Through the practical which done I discovered that the regularization is very important without do this the model which create will b
e poor. The various model which learned on this week such as 
*	Dropout
* Early stopping
*	Batch Normalization


The above mentioned as the method which used in regularization in in older to avoid overfitting the regularization help the optimization
in older to produce the model which is better in train and test. Apart from learned the regularization and also learned about the   CNN 
is come to improve MLP which has addition layers known as convolution layers which help in visualize the data. The CNN is more powerful 
due to this visualize the data in 1D data,2D data and 3D data. The CNN has four layers as following
*	Convolution Layer 
* Detector stage layer
*	Pooling layer
*	Full connected layer

The CNN is more applicable compare MLP due to wide range of application such as object detection, object recognition, object segmentation,
face detection, image captioning, action classification, video caption and others. 

On RNN learned about that this family of neural network for handling sequential data. It uses as the CNN due to the parameter sharing. 
On RNN learned about how to create model, train model, visualization and test mode but learned this through video conference which 
operated by MR Sambaiga.

Challenge of this week this week it was very difficult compare last week, CNN it needs more practice in older to understand more.
Through this we decided to do the discussion in older to understand more for my self this method help me. I suggest to
has video conference at least once per week.
